---
title: "Pierce County Property Analysis: Data Loading"
subtitle: "Step 1: Acquiring and Loading Raw Data"
author: "Your Group Name"
date: "today"
format: 
  html:
    toc: true
    toc-depth: 3
    theme: cosmo 
    code-fold: true
    code-summary: "Show/Hide Code"
    df-print: kable # For nice table printing with knitr::kable
editor: source
execute:
  echo: true
  warning: false   # Suppress warnings globally for now
  message: false   # Suppress messages globally for now
  error: true      # Display errors if they occur
---

# 1. Introduction

This document outlines the first step in our analysis of Pierce County property data: loading all raw data files into a DuckDB in-memory database. Each text file will be loaded into its own table with column names derived from the provided metadata (PDFs). All columns will initially be loaded as `VARCHAR` (text) to ensure robust loading; type conversions will occur during the subsequent cleaning phase.

# 2. Setup and Configuration

## 2.1. Load Libraries and Functions

First, we load necessary R packages and our custom data loading function.

```{r}
#| label: setup-load-libs-funcs

# Ensure these packages are installed: install.packages(c("DBI", "duckdb", "knitr", "dplyr"))
library(DBI)
library(duckdb)
library(knitr) # For kable()
library(dplyr) # For glimpse() later

# Source our custom data loading function
# The path is relative to the Quarto document's location (reports/)
source("../R/00_load_data_functions.R")

```

## 2.2. Define File Paths and Column Names

Here, we define the locations of our raw data files and the column names for each table. IMPORTANT: You MUST verify and complete the col_names_lists with the correct column names in the correct order for EACH of your files based on your metadata PDFs.

```{r}
#| label: setup-file-configs

# Base path to the directory where the raw .txt files are stored
# This path is relative to the project root, assuming the .Rproj is in the root.
# If running the .qmd directly, ensure this path correctly points to your data/raw folder.
# For Quarto rendering, it's often best to assume the project root is the working directory.
# Let's construct paths assuming the Quarto doc is in 'reports/' and data is in 'data/raw/'
# relative to a common project root.
project_root_relative_data_path <- "../data/raw/" # Path from 'reports/' dir to 'data/raw/'

file_paths_list <- list(
  sale = paste0(project_root_relative_data_path, "sale.txt"),
  appraisal_account = paste0(project_root_relative_data_path, "appraisal_account.txt"),
  improvement = paste0(project_root_relative_data_path, "improvement.txt"),
  improvement_detail = paste0(project_root_relative_data_path, "improvement_detail.txt"),
  improvement_builtas = paste0(project_root_relative_data_path, "improvement_builtas.txt"),
  land_attribute = paste0(project_root_relative_data_path, "land_attribute.txt"),
  seg_merge = paste0(project_root_relative_data_path, "seg_merge.txt"),
  tax_account = paste0(project_root_relative_data_path, "tax_account.txt"),
  tax_description = paste0(project_root_relative_data_path, "tax_description.txt")
)

# --- COLUMN NAMES ---
# !!! ACTION REQUIRED: Populate these lists accurately for EACH file !!!
# The order of names MUST match the order of columns in your .txt files.
# These are placeholders. Refer to your PDF metadata.
col_names_lists <- list(
  sale = c(
    "ETN", "Parcel_Count", "Parcel_Number", "Sale_Date_Raw", "Sale_Price_Raw", 
    "Deed_Type", "Grantor", "Grantee", "Valid_Invalid_Raw", 
    "Confirmed_Uncomfirmed_Raw", # Note: "Uncomfirmed" as per PDF
    "Exclude_Reason", "Improved_Vacant_Raw", "Appraisal_Account_Type"
  ), 
  
  appraisal_account = c(
    "Parcel_Number", "Appraisal_Account_Type", "Business_Name", "Value_Area_ID", 
    "Land_Economic_Area", "Buildings", "Group_Account_Number", 
    "Land_Gross_Acres_Raw", "Land_Net_Acres_Raw", "Land_Gross_Square_Feet_Raw", 
    "Land_Net_Square_Feet_Raw", "Land_Gross_Front_Feet_Raw", "Land_Width_Raw", 
    "Land_Depth_Raw", "Submerged_Area_Square_Feet_Raw", "Appraisal_Date_Raw", 
    "Waterfront_Type", "View_Quality", "Utility_Electric", "Utility_Sewer", 
    "Utility_Water", "Street_Type", "Latitude_Raw", "Longitude_Raw"
  ), 
  
  improvement = c(
    "Parcel_Number", "Building_ID", "Property_Type", "Neighborhood", 
    "Neighborhood_Extension", "Square_Feet_Raw", "Net_Square_Feet_Raw", 
    "Percent_Complete_Raw", "Condition", "Quality", "Primary_Occupancy_Code_Raw", 
    "Primary_Occupancy_Description", "Mobile_Home_Serial_Number", 
    "Mobile_Home_Total_Length_Raw", "Mobile_Home_Make", 
    "Attic_Finished_Square_Feet_Raw", "Basement_Square_Feet_Raw", 
    "Basement_Finished_Square_Feet_Raw", "Carport_Square_Feet_Raw", 
    "Balcony_Square_Feet_Raw", "Porch_Square_Feet_Raw", 
    "Attached_Garage_Square_Feet_Raw", "Detached_Garage_Square_Feet_Raw", 
    "Fireplaces_Raw", "Basement_Garage_Door_Raw"
  ),
                 
  improvement_detail = c(
    "Parcel_Number", "Building_ID", "Detail_Type", "Detail_Description", "Units_Raw"
  ),
                        
  improvement_builtas = c(
    "Parcel_Number", "Building_ID", "Built_As_Number_Raw", "Built_As_ID_Raw", 
    "Built_As_Description", "Built_As_Square_Feet_Raw", "HVAC_Code_Raw", 
    "HVAC_Description", "Exterior", "Interior", "Stories_Raw", "Story_Height_Raw", 
    "Sprinkler_Square_Feet_Raw", "Roof_Cover", "Bedrooms_Raw", "Bathrooms_Raw", 
    "Units_Count_Raw", "Class_Code", "Class_Description", "Year_Built_Raw", 
    "Year_Remodeled_Raw", "Adjusted_Year_Built_Raw", "Physical_Age_Raw", 
    "Built_As_Length_Raw", "Built_As_Width_Raw", "Mobile_Home_Model"
  ),
                         
  land_attribute = c(
    "Parcel_Number", "Attribute_Key", "Attribute_Description"
  ), 
                    
  seg_merge = c(
    "Seg_Merge_Number", "Parent_Child_Indicator", "Parcel_Number", 
    "Continued_Indicator", "Completed_Date_Raw", "Tax_Year_Raw"
  ), 
               
  tax_account = c(
    "Parcel_Number", "Account_Type", "Property_Type", "Site_Address", 
    "Use_Code", "Use_Description", "Tax_Year_Prior_Raw", 
    "Tax_Code_Area_Prior_Year", "Exemption_Type_Prior_Year", 
    "Current_Use_Code_Prior_Year", "Land_Value_Prior_Year_Raw", 
    "Improvement_Value_Prior_Year_Raw", "Total_Market_Value_Prior_Year_Raw", 
    "Taxable_Value_Prior_Year_Raw", "Tax_Year_Current_Raw", 
    "Tax_Code_Area_Current_Year", "Exemption_Type_Current_Year", 
    "Current_Use_Code_Current_Year", "Land_Value_Current_Year_Raw", 
    "Improvement_Value_Current_Year_Raw", "Total_Market_Value_Current_Year_Raw", 
    "Taxable_Value_Current_Year_Raw", "Range", "Township", "Section", 
    "Quarter_Section", "Subdivision_Name", "Located_On_Parcel"
  ), 
                 
  tax_description = c(
    "Parcel_Number", "Line_Number_Raw", "Tax_Description_Line"
  )
)

# Verify all files have column name definitions (basic check)
if (!all(names(file_paths_list) %in% names(col_names_lists))) {
  stop("Mismatch between file_paths_list and col_names_lists. Ensure every file has a corresponding column name definition.")
}
if (!all(names(col_names_lists) %in% names(file_paths_list))) {
  stop("Mismatch between col_names_lists and file_paths_list. Ensure every column name definition has a corresponding file.")
}
```

## 2.3. Initialize DuckDB Connection

We'll use an in-memory DuckDB database for this session.

```{r}
#| label: setup-duckdb-connection

con <- DBI::dbConnect(duckdb::duckdb(), dbdir = ":memory:")
cat("DuckDB in-memory connection established.\n")
```

# 3. Load Raw Data into DuckDB

Now, we iterate through our configured files and load each one into a separate table in DuckDB using our custom function.

```{r}
#| label: load-data-to-duckdb
#| results: 'asis' # Allows cat() HTML output to render directly

cat("### Starting Data Loading Process:\n\n")

loaded_successfully <- c() # To track which tables loaded

for (table_key in names(file_paths_list)) {
  file_path <- file_paths_list[[table_key]]
  col_names <- col_names_lists[[table_key]]
  target_table_name <- paste0(table_key, "_raw_duckdb") # e.g., "sale_raw_duckdb"
  
  cat(paste0("Attempting to load: ", basename(file_path), " into table `", target_table_name, "`...\n"))
  
  if (is.null(col_names) || length(col_names) == 0) {
      cat(paste0("<p style='color:red;'><strong>Error:</strong> Column names for '", table_key, "' are not defined or empty. Skipping.</p>\n\n"))
      loaded_successfully[target_table_name] <- FALSE
      next
  }
  
  success <- load_pipe_delimited_file_to_duckdb(
    con = con,
    file_path = file_path,
    col_names_vector = col_names,
    target_table_name = target_table_name
  )
  loaded_successfully[target_table_name] <- success
}

cat("\n### Data Loading Process Complete.\n")

# Summary of loading
cat("\n#### Loading Summary:\n")
for(tbl_name in names(loaded_successfully)){
    status_msg <- if(loaded_successfully[tbl_name]) "Successfully loaded" else "Failed to load or file not found"
    cat(paste0("- `", tbl_name, "`: ", status_msg, "\n"))
}
```

# 4. Preliminary Data Inspection

Let's list the tables in our DuckDB database and look at the first few rows and structure of each loaded table to verify the loading process.

```{r}
#| label: inspect-loaded-tables
#| results: 'asis'

cat("\n### Tables in DuckDB:\n")
loaded_tables_in_db <- DBI::dbListTables(con)
if (length(loaded_tables_in_db) > 0) {
  kable(loaded_tables_in_db, col.names = "Table Name", caption = "Tables present in DuckDB") %>% print()
} else {
  cat("No tables found in DuckDB. Please check loading logs.\n")
}


cat("\n\n### Preview of Loaded Tables (First 3 Rows and Structure):\n")
for (table_name_raw in loaded_tables_in_db) {
  # Only preview tables we attempted to load based on our naming convention
  if (grepl("_raw_duckdb$", table_name_raw) && isTRUE(loaded_successfully[table_name_raw])) {
    cat(paste0("\n#### Table: `", table_name_raw, "`\n"))
    
    # Get column count from DB
    db_cols <- DBI::dbListFields(con, table_name_raw)
    num_db_cols <- length(db_cols)
    
    # Get defined column count
    original_key <- sub("_raw_duckdb$", "", table_name_raw) # e.g. "sale" from "sale_raw_duckdb"
    num_defined_cols <- length(col_names_lists[[original_key]])

    cat(paste0("*Defined columns: ", num_defined_cols, ", Columns in DB table: ", num_db_cols, "*\n"))
    if (num_defined_cols != num_db_cols && num_db_cols > 0) {
         cat(paste0("<p style='color:orange;'><strong>Warning:</strong> Mismatch in column count for `", table_name_raw, 
                    "`. Defined: ", num_defined_cols, ", Actual in DB: ", num_db_cols, 
                    ". This could indicate issues with delimiter, quoting, or column name definitions.</p>"))
    }

    # Preview first 3 rows
    cat("\n##### First 3 Rows:\n")
    tryCatch({
      preview_data <- DBI::dbGetQuery(con, paste0("SELECT * FROM ", table_name_raw, " LIMIT 3"))
      if (nrow(preview_data) > 0) {
        kable(preview_data, caption = paste("First 3 rows of", table_name_raw)) %>% 
          kableExtra::kable_styling(bootstrap_options = c("striped", "condensed", "responsive"), 
                                    full_width = FALSE,
                                    font_size = 10) %>% # Smaller font for wide tables
          print()
      } else {
        cat("Table is empty or could not retrieve rows.\n")
      }
    }, error = function(e) {
      cat(paste0("<p style='color:red;'>Error previewing table `", table_name_raw, "`: ", e$message, "</p>\n"))
    })
    
    # Show structure (column names and types from DuckDB's perspective)
    cat("\n##### Structure (from DuckDB):\n")
    tryCatch({
        # DuckDB's PRAGMA table_info('table_name') is good for this
        structure_info <- DBI::dbGetQuery(con, paste0("PRAGMA table_info('", table_name_raw, "');"))
        if (nrow(structure_info) > 0) {
            kable(structure_info %>% select(name, type), caption = paste("Structure of", table_name_raw)) %>% 
              kableExtra::kable_styling(bootstrap_options = c("condensed"), full_width = FALSE) %>%
              print()
        } else {
            cat("Could not retrieve structure information.\n")
        }
    }, error = function(e) {
      cat(paste0("<p style='color:red;'>Error getting structure for table `", table_name_raw, "`: ", e$message, "</p>\n"))
    })
    cat("\n---\n") # Separator
  }
}
```

# 5. EDA Preparation

Read the comments at the beginning of each code chunk.


```{r}
# select 80k Appraisal_Account records and join the latest Sale record
# There appears some Error with empty values in
# appraisal_account_raw_duckdb (relevant) -- it works however with the first 80k rows
# tax_account_raw_duckdb (irrelevant)
# tax_description_raw_duckdb (irrelevant)

# get list of tables
DBI::dbListTables(con)

# retrieve apraisal_account_raw_duckdb
appraisal_account <- DBI::dbGetQuery(con, "SELECT * FROM appraisal_account_raw_duckdb limit 80000")

# retrieve sale_raw_duckdb and join on Parcel_Number
sales <- DBI::dbGetQuery(con, "SELECT * FROM sale_raw_duckdb")
sales <- appraisal_account %>%
  dplyr::inner_join(sales, by = "Parcel_Number") 

# get the most recent sale per parcel
sales <- sales %>%
  dplyr::group_by(Parcel_Number) %>%
  dplyr::slice_max(Sale_Date_Raw, n = 1) %>%
  dplyr::ungroup()

# drop Parcels that appear more than once
sales <- sales %>%
  dplyr::group_by(Parcel_Number) %>%
  dplyr::mutate(Count = n()) %>%
  dplyr::filter(Count == 1) %>%
  dplyr::ungroup() %>%
  dplyr::select(-Count)

# print unique parcels
unique_parcels <- unique(sales$Parcel_Number)
cat(paste0("Unique parcels in the most recent sales: ", length(unique_parcels), "\n"))

```

```{r}
# select improvement_builtas_raw_duckdb and improvement_raw_duckdb and join on Parcel_Number add Building_ID

improvement <- DBI::dbGetQuery(con, "SELECT * FROM improvement_raw_duckdb")
improvement_builtas <- DBI::dbGetQuery(con, "SELECT * FROM improvement_builtas_raw_duckdb")
improvement <- improvement %>%
  dplyr::inner_join(improvement_builtas, by = c("Parcel_Number", "Building_ID"))
improvement <- improvement %>%
  dplyr::group_by(Parcel_Number) %>%
  dplyr::slice_max(Year_Built_Raw, n = 1) %>%
  dplyr::ungroup()
```

```{r}  
# join improvement and sales on Parcel_Number
# filter for Residential, Valid, Improved
# TODO: currently double Parcel_Number are dropped. check if this is correct (mutliple improvements). but must have just one anyway
# 21k Rows left for EDA

full_data <- sales %>%
  dplyr::inner_join(improvement, by = "Parcel_Number") %>%
  dplyr::filter(Appraisal_Account_Type.x == "Residential") %>%
  dplyr::filter(Valid_Invalid_Raw == "1") %>%
  dplyr::filter(Improved_Vacant_Raw == "1")

#drop Parcels that appear more than once
full_data <- full_data %>%
  dplyr::group_by(Parcel_Number) %>%
  dplyr::mutate(Count = n()) %>%
  dplyr::filter(Count == 1) %>%
  dplyr::ungroup() %>%
  dplyr::select(-Count)

# print unique parcels
unique_parcels <- unique(full_data$Parcel_Number)
cat(paste0("Unique parcels in the most recent sales: ", length(unique_parcels), "\n"))

full_data <- full_data %>%
  dplyr::select(Parcel_Number, Sale_Date_Raw, Sale_Price_Raw, Year_Built_Raw, Bedrooms_Raw, Bathrooms_Raw, Square_Feet_Raw, 
                Latitude_Raw, Longitude_Raw, Neighborhood, View_Quality, Stories_Raw, Adjusted_Year_Built_Raw, Quality, Condition, 
                Utility_Electric, Utility_Sewer, Utility_Water, Street_Type, Valid_Invalid_Raw, Improved_Vacant_Raw)
```
```{r}  
# Convert to the right data types
# this could be stored in DB, csv etc. and loaded in the future

full_data <- full_data %>%
  mutate(
    Sale_Date_Raw = as.Date(Sale_Date_Raw, format = "%m/%d/%Y"),
    Sale_Price_Raw = as.numeric(Sale_Price_Raw),
    Year_Built_Raw = as.numeric(Year_Built_Raw),
    Adjusted_Year_Built_Raw = as.numeric(Adjusted_Year_Built_Raw),
    Bedrooms_Raw = as.numeric(Bedrooms_Raw),
    Bathrooms_Raw = as.numeric(Bathrooms_Raw),
    Square_Feet_Raw = as.numeric(Square_Feet_Raw),
    Latitude_Raw = as.numeric(Latitude_Raw),
     Stories_Raw = as.numeric(Stories_Raw), 
    Longitude_Raw = as.numeric(Longitude_Raw),
    Neighborhood = as.factor(Neighborhood),
    View_Quality = as.factor(View_Quality),
    Quality = as.factor(Quality),
    Condition = as.factor(Condition),
    Utility_Electric = as.factor(Utility_Electric),
    Utility_Sewer = as.factor(Utility_Sewer),
    Utility_Water = as.factor(Utility_Water),
    Street_Type = as.factor(Street_Type),
    Valid_Invalid_Raw = as.factor(Valid_Invalid_Raw),
    Improved_Vacant_Raw = as.factor(Improved_Vacant_Raw)
  )
```

# EDA

### Importing Libraries for EDA
```{r}
library(tigris)
library(sf)
library(dplyr)
library(ggplot2)
library(viridis)
library(scales)
library(grid)
library(GGally)
library(tidyr)
```


## Size & Structure

### Square Feet

```{r}
ggplot(full_data, aes(x = Square_Feet_Raw)) +
  geom_histogram(binwidth = 100, fill = "#1F77B4", color = "black", alpha = 0.7) +
  scale_x_continuous(labels = scales::comma) +
  labs(
    title = "Distribution of Square Footage",
    x = "Square Feet",
    y = "Count"
  ) +
  theme_minimal()
```

#### Square Footage vs. Sale Price
```{r}
ggplot(full_data, aes(x = Square_Feet_Raw, y = Sale_Price_Raw)) +
  geom_point(alpha = 0.3, color = "#1f77b4") +
  scale_y_continuous(labels = scales::dollar) +
  scale_x_continuous(labels = scales::comma) +
  labs(title = "Sale Price vs. Square Footage", x = "Square Feet", y = "Sale Price") +
  theme_minimal()
```


### Bedrooms

```{r}
ggplot(full_data, aes(x = factor(Bedrooms_Raw), fill = factor(Bedrooms_Raw))) +
  geom_bar(color = "black", alpha = 0.8) +
  scale_fill_brewer(palette = "Pastel1") +
  labs(
    title = "Number of Bedrooms",
    x = "Bedrooms",
    y = "Count",
    fill = "Bedrooms"
  ) +
  theme_minimal()
```

#### Sale Price vs. Bedrooms 
```{r}
ggplot(full_data, aes(x = factor(Bedrooms_Raw), y = Sale_Price_Raw)) +
  geom_boxplot(fill = "#2ca02c", alpha = 0.6) +
  scale_y_log10(labels = scales::dollar) +
  labs(title = "Sale Price by Number of Bedrooms", x = "Bedrooms", y = "Sale Price (log10)") +
  theme_minimal()
```


### Bathrooms

```{r}
ggplot(full_data, aes(x = Bathrooms_Raw)) +
  geom_histogram(binwidth = 0.25, fill = "#E377C2", color = "black", alpha = 0.7) +
  scale_x_continuous(breaks = seq(0, max(full_data$Bathrooms_Raw, na.rm = TRUE), by = 0.5)) +
  labs(
    title = "Number of Bathrooms",
    x = "Bathrooms",
    y = "Count"
  ) +
  theme_minimal()
```

#### Sale Price vs. Bathrooms

```{r}
ggplot(full_data, aes(x = factor(Bathrooms_Raw), y = Sale_Price_Raw)) +
  geom_boxplot(fill = "#9467bd", alpha = 0.6) +
  scale_y_log10(labels = scales::dollar) +
  labs(
    title = "Sale Price by Number of Bathrooms",
    x = "Bathrooms",
    y = "Sale Price (log10)"
  ) +
  theme_minimal()
```


### Stories

```{r}
ggplot(full_data, aes(x = factor(Stories_Raw), fill = factor(Stories_Raw))) +
  geom_bar(color = "black", alpha = 0.8) +
  scale_fill_brewer(palette = "Set2") +
  labs(
    title = "Number of Stories",
    x = "Stories",
    y = "Count",
    fill = "Stories"
  ) +
  theme_minimal()
```


#### Sale Price vs. Stories

```{r}
ggplot(full_data, aes(x = factor(Stories_Raw), y = Sale_Price_Raw, fill = factor(Stories_Raw))) +
  geom_boxplot(alpha = 0.7) +
  scale_y_log10(labels = scales::dollar) +
  scale_fill_brewer(palette = "Pastel2") +
  labs(
    title = "Sale Price by Number of Stories",
    x = "Stories",
    y = "Sale Price (log scale)",
    fill = "Stories"
  ) +
  theme_minimal()
```



### Correlation Matrix

```{r}
numeric_vars <- full_data %>%
  select(Sale_Price_Raw, Square_Feet_Raw, Bedrooms_Raw, Bathrooms_Raw, Stories_Raw) %>%
  na.omit()

ggpairs(numeric_vars, 
        lower = list(continuous = wrap("points", alpha = 0.3)), 
        diag = list(continuous = "densityDiag"), 
        upper = list(continuous = "cor"))
```


### Boxplots for Outlier Detection

```{r}
boxplot_stats <- full_data %>%
  select(Square_Feet_Raw, Bedrooms_Raw, Bathrooms_Raw, Stories_Raw) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Value") %>%
  ggplot(aes(x = Variable, y = Value)) +
  geom_boxplot(fill = "#d62728", alpha = 0.6) +
  coord_flip() +
  labs(title = "Boxplots for Outlier Detection", y = "Value", x = "")
boxplot_stats
```



## Location 

### Mapping Median Price per Sqft Across Pierce County

```{r warning=FALSE}} 
# 1. Load Pierce County boundary (Washington = '53')
pierce_county <- counties(state = "53", cb = TRUE) %>%
  filter(NAME == "Pierce")

# 2. Convert full_data to sf object with WGS84 CRS
full_data_sf <- full_data %>%
  mutate(
    Longitude_Raw = as.numeric(Longitude_Raw),
    Latitude_Raw = as.numeric(Latitude_Raw)
  ) %>%
  st_as_sf(coords = c("Longitude_Raw", "Latitude_Raw"), crs = 4326, remove = FALSE)

# 3. Transform Pierce County CRS to match full_data
pierce_county <- st_transform(pierce_county, st_crs(full_data_sf))

# 4. Keep only points within Pierce County
full_data_sf <- full_data_sf[st_within(full_data_sf, pierce_county, sparse = FALSE), ]

# 5. Get bounding box
lat_range <- st_bbox(pierce_county)[c("ymin", "ymax")]
lon_range <- st_bbox(pierce_county)[c("xmin", "xmax")]

# 6. Define bin edges
num_bins <- 80
lat_bins <- seq(lat_range[1], lat_range[2], length.out = num_bins + 1)
lon_bins <- seq(lon_range[1], lon_range[2], length.out = num_bins + 1)

# 7. Bin data and compute average price per sqft
full_data_sf <- full_data_sf %>%
  mutate(
    Price_per_sqft = Sale_Price_Raw / Square_Feet_Raw,
    Lat_bin = cut(Latitude_Raw, breaks = lat_bins, include.lowest = TRUE),
    Lon_bin = cut(Longitude_Raw, breaks = lon_bins, include.lowest = TRUE)
  ) %>%
  filter(Square_Feet_Raw >= 100)   # example threshold: ignore values > 1000

# 8. Aggregate by bin and extract bin boundaries
heatmap_data <- full_data_sf %>%
  filter(Square_Feet_Raw >= 100) %>%   # example threshold: ignore values > 1000
  group_by(Lat_bin, Lon_bin) %>%
  summarize(
    Avg_Price_sqft = median(Price_per_sqft, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    ymin = as.numeric(sub("\\((.+),.*", "\\1", Lat_bin)),
    ymax = as.numeric(sub(".*,([^]]*)\\]", "\\1", Lat_bin)),
    xmin = as.numeric(sub("\\((.+),.*", "\\1", Lon_bin)),
    xmax = as.numeric(sub(".*,([^]]*)\\]", "\\1", Lon_bin))
  )

# 9. Plot the heatmap using geom_rect
# Calculate log breaks evenly spaced along the log scale
log_min <- min(log(heatmap_data$Avg_Price_sqft), na.rm = TRUE)
log_max <- max(log(heatmap_data$Avg_Price_sqft), na.rm = TRUE)

# Generate 5 evenly spaced breaks on log scale
log_breaks <- seq(log_min, log_max, length.out = 5)
# Convert breaks back to original scale for labeling
legend_labels <- scales::dollar(exp(log_breaks))

ggplot() +
  geom_sf(data = pierce_county, fill = "white", color = "black", size = 0.6) +
  geom_rect(
    data = heatmap_data,
    aes(
      xmin = xmin, xmax = xmax,
      ymin = ymin, ymax = ymax,
      fill = log(Avg_Price_sqft)  # fill is log-transformed
    ),
    alpha = 0.85,
    color = NA
  ) +
  scale_fill_viridis_c(
    option = "magma",
    trans = "identity",           # no further transformation, since fill is already log
    breaks = log_breaks,          # breaks evenly spaced in log scale
    labels = legend_labels,       # labels in original scale
    na.value = "grey90",
    name = "Price per sqft"
  ) +
  coord_sf(xlim = lon_range, ylim = lat_range, expand = FALSE) +
  labs(
    title = "Median Prices of Houses",
    subtitle = "in Pierce County",
    x = "Longitude",
    y = "Latitude"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(face = "bold", size = 18, hjust = 0.5, margin = margin(b = 4)),
    plot.subtitle = element_text(size = 14, hjust = 0.5, margin = margin(b = 12)),
    axis.title = element_text(face = "italic", size = 12),
    axis.text.x = element_text(angle = 45, hjust = 1, size = 9),
    axis.text.y = element_text(size = 9),
    legend.title = element_text(face = "bold", size = 12),
    legend.text = element_text(size = 10),
    legend.key.height = unit(1, "cm"),  # increase legend height here
    panel.grid.major = element_line(color = "gray80", size = 0.3),
    panel.grid.minor = element_blank()
  )
```

### View Quality

```{r}
# Beispiel: Kategorien in gewünschter Reihenfolge
view_levels <- c(
  "NA",
  "View Lim -",
  "View Lim",
  "View Lim +",
  "View Avg",
  "View Avg +",
  "View Good",
  "View Good +",
  "View V-Good"
)

# Faktor mit Reihenfolge erstellen
full_data_sf <- full_data_sf %>%
  mutate(
    View_Quality = factor(View_Quality, levels = view_levels)
  )

# Quantile berechnen
quantiles <- quantile(full_data_sf$Price_per_sqft, probs = c(0.01, 0.99), na.rm = TRUE)

# Daten filtern auf 1%-99% Quantil
filtered_data <- full_data_sf %>%
  filter(Price_per_sqft >= quantiles[1], Price_per_sqft <= quantiles[2])

# Boxplot with improved aesthetics
ggplot(filtered_data, aes(x = View_Quality, y = Price_per_sqft)) +
  geom_boxplot(fill = "#2C3E50", color = "black", alpha = 0.6, width = 0.7) +
  scale_y_log10(
    limits = c(quantiles[1], quantiles[2]),
    breaks = scales::trans_breaks("log10", function(x) 10^x),
    labels = scales::label_number(scale_cut = scales::cut_short_scale())
  ) +
  coord_cartesian(ylim = c(quantiles[1], 2000)) +
  labs(
    title = "House Price per Square Foot by View Quality",
    subtitle = "",
    x = "View Quality",
    y = "Price per sqft"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 12, color = "gray40"),
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid.major.y = element_line(color = "gray85"),
    panel.grid.minor.y = element_blank(),
    axis.line = element_line(color = "gray60"),
    panel.border = element_blank()
  )
```

### Neighborhood

```{r}
# Calculate median price per sqft by neighborhood
median_prices <- full_data_sf %>%
  group_by(Neighborhood) %>%
  summarize(median_price = median(Price_per_sqft, na.rm = TRUE)) %>%
  arrange(desc(median_price))

# Select top and bottom 10 neighborhoods
top_bottom_neigh <- bind_rows(
  head(median_prices, 10),
  tail(median_prices, 10)
)

# Filter main data to just those neighborhoods and set factor levels
filtered_data <- full_data_sf %>%
  filter(Neighborhood %in% top_bottom_neigh$Neighborhood) %>%
  mutate(Neighborhood = factor(Neighborhood, levels = top_bottom_neigh$Neighborhood))

# --- Option 1: Boxplot for Top & Bottom 10 Neighborhoods ---
ggplot(filtered_data, aes(x = Neighborhood, y = Price_per_sqft)) +
  geom_boxplot(outlier.shape = NA, fill = "#2980B9", color = "#1C2833", alpha = 0.6) +
  coord_flip(ylim = c(0, 2000)) +
  labs(
    title = "Top & Bottom 10 Neighborhoods by Median Price per Sqft",
    x = "Neighborhood",
    y = "Price per sqft"
  ) +
  theme_minimal(base_size = 12)

# --- Option 2: Summary Table ---
summary_table <- full_data_sf %>%
  group_by(Neighborhood) %>%
  summarize(
    n = n(),
    median_pps = median(Price_per_sqft, na.rm = TRUE),
    IQR_pps = IQR(Price_per_sqft, na.rm = TRUE)
  ) %>%
  arrange(desc(median_pps))

print(head(summary_table, 10))  # Top 10 neighborhoods by median
# View(summary_table)  # Optional: Open in RStudio viewer

# --- Option 3: Histogram of Neighborhood Medians ---
ggplot(median_prices, aes(x = median_price)) +
  geom_histogram(binwidth = 25, fill = "#1ABC9C", color = "white") +
  labs(
    title = "Distribution of Median Price per Sqft Across Neighborhoods",
    x = "Median Price per sqft",
    y = "Number of Neighborhoods"
  ) +
  theme_minimal(base_size = 13)

```


## Utilities

### Utility Water

```{r}
# Create boxplots per category of water utility
ggplot(full_data_sf, aes(x = Price_per_sqft, y = Utility_Water)) +
  geom_boxplot() +
  scale_x_log10(labels = scales::dollar) +
  labs(
    title = "House Price per Square Foot by Water Utility",
    x = "Price per sqft",
    y = "Water Utility"
  ) +
  theme_minimal(base_size = 21)

```

### Utility Electric
```{r}
# Create boxplots per category of electric utility
ggplot(full_data_sf, aes(x = Price_per_sqft, y = Utility_Electric)) +
  geom_boxplot() +
  scale_x_log10(labels = scales::dollar) +
  labs(
    title = "House Price per Square Foot by Electric Utility",
    x = "Price per sqft",
    y = "Electric Utility"
  ) +
  theme_minimal(base_size = 21) 
```

### Utility Sewer
```{r}
# Create boxplots per category of sewer utility
ggplot(full_data_sf, aes(x = Price_per_sqft, y = Utility_Sewer)) +
  geom_boxplot() +
  scale_x_log10(labels = scales::dollar) +
  labs(
    title = "House Price per Square Foot by Sewer Utility",
    x = "Price per sqft",
    y = "Sewer Utility"
  ) +
  theme_minimal(base_size = 21)
```

### Street type

```{r}
# Create boxplots per category of street type
ggplot(full_data_sf, aes(x = Price_per_sqft, y = Street_Type)) +
  geom_boxplot() +
  scale_x_log10(labels = scales::dollar) +
  labs(
    title = "House Price per Square Foot by Street Type",
    x = "Price per sqft",
    y = "Street Type"
  ) +
  theme_minimal(base_size = 21)

```

## Target Variable

### Sales Price
```{r}
#Create a histogram of the sales price
ggplot(full_data_sf, aes(x = Sale_Price_Raw)) +
  geom_boxplot() +
  scale_x_log10(labels = scales::dollar) +
  labs(
    title = "Distribution of Sales Price",
    x = "Sales Price",
  ) +
  theme_minimal(base_size = 21) + 
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank())

```


### Sales Price per Square Foot
```{r}
ggplot(full_data_sf, aes(x = Price_per_sqft)) +
  geom_boxplot() +
  scale_x_log10(labels = scales::dollar) +
  labs(
    title = "Distribution of Sales Price",
    x = "Sales Price",
  ) +
  theme_minimal(base_size = 21)+
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank())

```

# 6. Close DuckDB Connection (End of Session)

```{r}
#| label: cleanup-duckdb-connection
#| echo: false 
#| include: false 

if (exists("con") && DBI::dbIsValid(con)) {
  DBI::dbDisconnect(con, shutdown = TRUE)
  cat("DuckDB connection closed.\n") # Message suppressed by include=false
}
rm(list = ls()) # Clean up environment


```
