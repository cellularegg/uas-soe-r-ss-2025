---
title: "Pierce County Property Analysis: Data Loading"
subtitle: "Step 1: Acquiring and Loading Raw Data"
author: "David Zelenay"
date: "today"
format: 
  html:
    toc: true
    toc-depth: 3
    theme: cosmo 
    code-fold: true
    code-summary: "Show/Hide Code"
    df-print: kable # For nice table printing with knitr::kable
editor: source
execute:
  echo: true
  warning: false   # Suppress warnings globally for now
  message: false   # Suppress messages globally for now
  error: true      # Display errors if they occur
---

# 1. Introduction

This document outlines the first step in our analysis of Pierce County property data: loading all raw data files into a DuckDB in-memory database. Each text file will be loaded into its own table with column names derived from the provided metadata (PDFs). All columns will initially be loaded as `VARCHAR` (text) to ensure robust loading; type conversions will occur during the subsequent cleaning phase.

# 2. Setup and Configuration

## 2.1. Load Libraries and Functions

First, we load necessary R packages and our custom data loading function.

```{r}
#| label: setup-load-libs-funcs

# Ensure these packages are installed: install.packages(c("DBI", "duckdb", "knitr", "dplyr"))
# library(DBI)
# library(duckdb)
library(knitr) # For kable()
library(dplyr) # For glimpse() later
# library(arrow)
```

```{r}
full_data <- read.csv("../data/final_data.csv")

cat("--- Data loaded successfully ---\n")
cat(paste("Number of rows:", nrow(full_data), "\n"))
cat(paste("Number of columns:", ncol(full_data), "\n"))

```


```{r}  
# Convert to the right data types
# this could be stored in DB, csv etc. and loaded in the future
quality_levels <- c("Low", "Low Plus", "Fair", "Fair Plus", "Average", "Average Plus", "Good", "Good Plus", "Very Good", "Very Good Plus", "Excellent"  )
condition_levels <- c("Uninhabitable", "Extra Poor", "Very Poor", "Poor", "Fair", "Average", "Good")
housing_data <- full_data %>%
  mutate(
    Sale_Date_Raw = as.Date(Sale_Date_Raw),
    Quality = factor(Quality, levels = quality_levels),
    Condition = factor(Condition, levels = condition_levels),
    Neighborhood = factor(Neighborhood, ordered = F),
    Street_Type = factor(Street_Type, ordered = F),
    Utility_Water = factor(Utility_Water, ordered = F),
    Utility_Electric = factor(Utility_Electric, ordered = F),
    Utility_Sewer = factor(Utility_Sewer, ordered = F),
    Improved_Vacant_Raw = as.logical(Improved_Vacant_Raw)
  ) %>%
  select(-Price_Per_SqFt)


str(housing_data)

```



```{r}
library(h2o)
h2o.init(
  nthreads = -1, # Use all available threads
  max_mem_size = "24G", # Adjust based on your system's memory
  # port = 54322 # Optional: specify a port if needed
)
```

```{r}
# Convert to H2O frame
h2o_data <- as.h2o(housing_data)

# Split data
splits <- h2o.splitFrame(h2o_data, ratios = 0.8, seed = 123)
train <- splits[[1]]
test <- splits[[2]]

```

```{r}

target <- "Sale_Price_Raw"
# Run AutoML
automl <- h2o.automl(
  x = setdiff(names(housing_data), target),
  y = target,
  training_frame = train,
  max_models = 25,
  nfolds = 10,
  stopping_metric = "MAE",
  sort_metric = "MAE",
  seed = 123,
  keep_cross_validation_predictions = FALSE,
  # preprocessing = list("standardize")
)

# Get best model
best_model <- automl@leader

# Make predictions
predictions <- h2o.predict(best_model, test)
# also calculate the MAPE
# Convert predictions and actual values to R vectors for MAPE calculation
pred_values <- as.vector(predictions)
actual_values <- as.vector(test$Sale_Price_Raw)
# Calculate MAPE manually
mape <- mean(abs((actual_values - pred_values) / actual_values)) * 100
cat("MAPE:", round(mape, 2), "%\n")
```

```{r}
automl@leaderboard
```

```{r}
# Assume aml is your H2O AutoML object
model_ids <- as.vector(automl@leaderboard$model_id[1:5])

for (model_id in model_ids) {
  model <- h2o.getModel(model_id)
  h2o.saveModel(object = model, path = "./saved-models/", filename = model_id, force = TRUE)
}
```

```{r}

# --- Evaluate all models in saved-models folder ---
model_dir <- "./saved-models/"
model_files <- list.files(model_dir, full.names = TRUE)

results <- data.frame(Model = character(), MAE = numeric(), RMSE = numeric(), MAPE = numeric(), stringsAsFactors = FALSE)

for (model_path in model_files) {
  model <- h2o.loadModel(model_path)
  preds <- h2o.predict(model, test)
  actuals <- as.vector(test$Sale_Price_Raw)
  pred_vals <- as.vector(preds)
  mae <- mean(abs(actuals - pred_vals))
  rmse <- sqrt(mean((actuals - pred_vals)^2))
  mape <- mean(abs((actuals - pred_vals) / actuals)) * 100
  results <- rbind(results, data.frame(Model = basename(model_path), MAE = mae, RMSE = rmse, MAPE = mape))
}

cat("\nModel Performance Summary:\n")
results


```


```{r}
h2o.shutdown()
```







